{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.stats import norm \n",
    "from jax import jit, vmap, value_and_grad\n",
    "from jax.example_libraries.optimizers import adam\n",
    "from jax.lax import scan \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Class for computing Kalman filtering under interacting FHN model\n",
    "### Consider the particle index is fixed. \n",
    "### Observable: X, rough, Hidden: Y, smooth\n",
    "\n",
    "class ips_fhn_filtering:\n",
    "    def __init__(self, dt_data):\n",
    "        self.step_size_data = dt_data\n",
    "    \n",
    "    def calc_coeff_mat_obs(self):\n",
    "        dt = self.step_size_data\n",
    "        return jnp.array(\n",
    "            [-dt]\n",
    "        )\n",
    "    \n",
    "    def calc_mean_obs(self, obs, θ, empirical_mean):\n",
    "        dt = self.step_size_data\n",
    "        *_, κ = θ\n",
    "        return obs + dt * (obs - obs**3 / 3 - κ*(obs-empirical_mean))  \n",
    "    \n",
    "    def calc_mean_hidden(self, obs, θ, empirical_mean):\n",
    "        dt = self.step_size_data\n",
    "        a, b, τ, σ, κ = θ\n",
    "        return ((obs + a)/τ)*dt + 0.5*dt**2*((obs- obs**3 / 3 - κ * (obs-empirical_mean))/τ - b*(obs + a)/(τ**2))\n",
    "\n",
    "\n",
    "    def matrix_A(self, θ):\n",
    "        a, b, τ, *_ = θ\n",
    "        dt = self.step_size_data\n",
    "        return jnp.array(\n",
    "            [\n",
    "                - dt,\n",
    "                1 - dt*b/τ + 0.5 * (dt**2)*(-1/τ + (b/τ)**2)\n",
    "            ]\n",
    "        ) \n",
    "    \n",
    "    def mean_one_step(self, obs, hidden, θ, empirical_mean):\n",
    "        A = self.matrix_A(θ)\n",
    "        a, b, τ, σ, κ = θ\n",
    "        dt = self.step_size_data\n",
    "\n",
    "        h_times_A = A * hidden\n",
    "\n",
    "        mean_vec = jnp.array([\n",
    "            self.calc_mean_obs(obs, θ, empirical_mean),\n",
    "            self.calc_mean_hidden(obs, θ, empirical_mean)\n",
    "            ])\n",
    "        \n",
    "        ret = mean_vec + h_times_A\n",
    "        return ret\n",
    "        \n",
    "    def covariance_one_step(self, θ):\n",
    "        dt = self.step_size_data\n",
    "        *_, τ, σ, κ = θ \n",
    "        return (σ**2) * jnp.array([\n",
    "            [dt, dt**2 / (2 * τ)], \n",
    "            [dt**2 / (2 * τ), (dt**3) / (3 * τ**2)]\n",
    "            ])\n",
    "    \n",
    "    def prediction_covariance(self, forward_filter_covariance, θ):\n",
    "        Σ =self.covariance_one_step(θ)\n",
    "        A = self.matrix_A(θ)\n",
    "        pred_cov =  Σ + (A @ A.T)*forward_filter_covariance\n",
    "        pred_cov_oo = pred_cov[0,0] # covariance of  (obs, obs) \n",
    "        pred_cov_ho = pred_cov[1,0] # covariance of  (hiden, obs) \n",
    "        pred_cov_hh = pred_cov[1,1] # covariance of  (hiden, hidden) \n",
    "        return pred_cov_oo, pred_cov_ho, pred_cov_hh\n",
    "    \n",
    "    \n",
    "    def prediction_mean(self, obs, forward_filter_mean, θ, empirical_mean):\n",
    "        pred_mean = self.mean_one_step(obs, forward_filter_mean, θ, empirical_mean) \n",
    "        pred_mean_obs = pred_mean[0]\n",
    "        pred_mean_hidden = pred_mean[1]\n",
    "        return pred_mean_obs, pred_mean_hidden\n",
    "    \n",
    "\n",
    "    def forward_filter_mean_cov_one_step(self, current_obs, next_obs, forward_filter_mean, forward_filter_covariance, θ, empirical_mean):\n",
    "        μ_o, μ_h = self.prediction_mean(current_obs, forward_filter_mean, θ, empirical_mean)\n",
    "        Λ_oo, Λ_ho, Λ_hh = self.prediction_covariance(forward_filter_covariance, θ) \n",
    "        next_filter_mean = μ_h + ((next_obs - μ_o)/Λ_oo)*Λ_ho\n",
    "        next_filter_cov = Λ_hh - (Λ_ho**2) / Λ_oo\n",
    "        return jnp.array([next_filter_mean]), jnp.array([next_filter_cov])\n",
    "    \n",
    "    \n",
    "    def forward_filter_mean_cov_paths_scan(self, obs_path, initial_mean, initial_cov, θ, empirical_mean_path):\n",
    "        @jit\n",
    "        def step_func(filter_mean_cov, path_current_next):\n",
    "            filter_mean, filter_cov = filter_mean_cov\n",
    "            obs_current, obs_next, empirical_mean_current = path_current_next\n",
    "            filter_next = self.forward_filter_mean_cov_one_step(obs_current, obs_next, filter_mean, filter_cov, θ, empirical_mean_current)     \n",
    "            return filter_next, filter_next \n",
    "        \n",
    "        _, filter_mean_cov = scan(step_func, (initial_mean, initial_cov), (obs_path[:-1], obs_path[1:], empirical_mean_path[:-1]))\n",
    "        filter_mean, filter_cov = filter_mean_cov\n",
    "\n",
    "        return jnp.concatenate((initial_mean[None], filter_mean)), jnp.concatenate((initial_cov[None], filter_cov)) \n",
    "    \n",
    "    \n",
    "    def get_contrast_function_fixed_index(self, θ, obs_path, initial_mean, initial_cov, empirical_mean_path):\n",
    "        filter_mean_path, filter_cov_path = self.forward_filter_mean_cov_paths_scan(obs_path, initial_mean, initial_cov, θ, empirical_mean_path)\n",
    "        initial_log_likelihood = norm.logpdf(obs_path[0], loc = obs_path[0], scale = 1.0)\n",
    "        Σ = self.covariance_one_step(θ)\n",
    "\n",
    "        @jit\n",
    "        def step_func(loglikelihood, qset_filtermeancov_empiricalmean):\n",
    "            q_current, q_next, filter_mean, filter_cov, empirical_mean = qset_filtermeancov_empiricalmean\n",
    "            A_q = self.calc_coeff_mat_obs()\n",
    "            q_mean = self.calc_mean_obs(q_current, θ, empirical_mean) + jnp.dot(A_q, filter_mean)\n",
    "            vec = filter_cov * A_q \n",
    "            scalar = jnp.dot(vec, A_q)\n",
    "            q_scale = jnp.sqrt(scalar + Σ[0,0])\n",
    "            loglikelihood_next = loglikelihood + norm.logpdf(q_next, q_mean, q_scale)\n",
    "            return loglikelihood_next, loglikelihood_next\n",
    "        \n",
    "        _, log_likelihood_seq = scan(step_func, initial_log_likelihood, (obs_path[:-1], obs_path[1:], filter_mean_path[:-1], filter_cov_path[:-1], empirical_mean_path[:-1])\n",
    "                                     )\n",
    "\n",
    "        return -2*log_likelihood_seq[-1]\n",
    "    \n",
    "    \n",
    "    def get_contrast_function(self, θ, obs_path_particles, initial_mean, initial_cov, empirical_mean_path):\n",
    "        contrast_function = jnp.sum(\n",
    "            vmap(self.get_contrast_function_fixed_index, (None, 1, None, None, None))(\n",
    "                θ, obs_path_particles, initial_mean, initial_cov, empirical_mean_path\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return contrast_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simulation-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the interaction term\n",
    "def interaction_term(v_i, v_j):\n",
    "    \"\"\"Compute the interaction term between two particles.\"\"\"\n",
    "    return v_j - v_i\n",
    "\n",
    "# Function to run a single simulation using JAX and scan\n",
    "def run_simulation(seed, num_particles, num_steps, dt, model_parameters, discard_steps=0):\n",
    "    # Set the random seed for reproducibility\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "\n",
    "    α = model_parameters['alpha']\n",
    "    β = model_parameters['beta']\n",
    "    τ = model_parameters['tau']\n",
    "    σ = model_parameters['sigma']\n",
    "    κ = model_parameters['kappa']\n",
    "\n",
    "    # Initialize variables\n",
    "    v = jnp.zeros(num_particles)  # Voltage-like variable\n",
    "    w = jnp.zeros(num_particles)  # Recovery-like variable\n",
    "\n",
    "    # Define the step function for scan\n",
    "    def step(carry, _):\n",
    "        v, w, key = carry\n",
    "\n",
    "        # Compute interaction terms using jax.vmap\n",
    "        def compute_interaction(v_all):\n",
    "            return jax.vmap(lambda v_i: jnp.sum(jax.vmap(lambda v_j: interaction_term(v_i, v_j))(v_all)))(v_all)\n",
    "\n",
    "        interaction = compute_interaction(v)\n",
    "\n",
    "        # Generate random noise\n",
    "        key, subkey = jax.random.split(key)\n",
    "        noise = jax.random.normal(subkey, shape=(num_particles,))\n",
    "\n",
    "        # Update FitzHugh-Nagumo equations with interaction and noise\n",
    "        dv = (v - v**3 / 3 - w + κ * interaction / num_particles) * dt + σ * jnp.sqrt(dt) * noise\n",
    "        dw = ((v + α - β * w) / τ) * dt\n",
    "\n",
    "        v = v + dv\n",
    "        w = w + dw\n",
    "\n",
    "        return (v, w, key), (v, w)\n",
    "\n",
    "    # Run the simulation using scan\n",
    "    (v_final, w_final, _), (v_history, w_history) = jax.lax.scan(step, (v, w, key), jnp.arange(num_steps))\n",
    "\n",
    "    # Combine v and w into pairs for each particle at each time step\n",
    "    vw_pairs = jnp.stack((v_history, w_history), axis=-1)  # Shape: (num_steps, num_particles, 2)\n",
    "    return vw_pairs[discard_steps:, :, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "\n",
    "def showplots(x_seq_sim, x_seq_obs, t_seq_sim, t_seq_obs):\n",
    "    \"\"\"Plot the voltage-like and recovery-like variables.\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(t_seq_sim, x_seq_sim, '.', alpha=0.5, markersize=0.5)\n",
    "    plt.plot(t_seq_obs, x_seq_obs, '.', alpha=0.5, markersize=0.5)\n",
    "    plt.title('Voltage-like Variable (v) Over Time')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('v')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation setting \n",
    "num_particles = 100  # Number of particles\n",
    "dt_sim = 0.0005            # Time step for simulation \n",
    "dt_obs = 0.005          # Time step for observation (subsampling) \n",
    "num_steps = 60000     # Number of time steps for simulation\n",
    "discard_steps = 0 # Steps to discard for initial transients  \n",
    "initial_mean = jnp.array([0.0]) \n",
    "initial_cov = jnp.array([1.0]) \n",
    "\n",
    "# FitzHugh-Nagumo model parameters\n",
    "α = 0.2  # Parameter controlling excitability\n",
    "β = 0.8  # Parameter controlling recovery\n",
    "τ = 1.5  # Timescale for recovery variable\n",
    "σ = 0.5  # Noise strength\n",
    "κ = 2.0  # Strength of interaction between particles\n",
    "\n",
    "model_parameters = {'alpha': α, 'beta': β, 'tau': τ, 'sigma': σ, 'kappa': κ} \n",
    "\n",
    "num_iter = 100\n",
    "θ_seq_lg = np.zeros((5, num_iter))\n",
    "θ_seq_em = np.zeros((5, num_iter))\n",
    "\n",
    "sub_interval = int(dt_obs/dt_sim) \n",
    "t_seq_sim = np.arange(discard_steps, num_steps) * dt_sim \n",
    "t_seq_obs = t_seq_sim[::sub_interval] \n",
    "\n",
    "ips_fhn = ips_fhn_filtering(dt_obs)\n",
    "\n",
    "θ_true = jnp.array([model_parameters['alpha'], model_parameters['beta'], model_parameters['tau'], model_parameters['sigma'], model_parameters['kappa']]) \n",
    "\n",
    "xy_seq_particles_sim = run_simulation(seed=int(20250625), \n",
    "num_particles=num_particles, num_steps=num_steps, dt=dt_sim, model_parameters=model_parameters, discard_steps=discard_steps)\n",
    "\n",
    "x_seq_particles_sim = xy_seq_particles_sim[:, :, 0]  # Voltage variable\n",
    "# Run simulation for each iteration\n",
    "x_seq_particles_obs = x_seq_particles_sim[::sub_interval, :]  # Downsampled for observation\n",
    "\n",
    "empirical_mean_seq = x_seq_particles_obs[:, :].mean(axis=1)  # Mean of v over time for all particles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_contrast_estimator(objective_func, obs_path_particles, θ_0, initial_mean, initial_cov, empirical_mean_seq, optimizer=adam, n_steps=5000, step_size= 0.005):\n",
    "    optimizer_init, optimizer_update, optimizer_get_params = optimizer(step_size) \n",
    "\n",
    "    @jit\n",
    "    def optimizer_step(state, obs_path_particles, initial_mean, initial_cov, empirical_mean_seq, step_index):\n",
    "        value, grad = value_and_grad(objective_func)(\n",
    "            optimizer_get_params(state), obs_path_particles, initial_mean, initial_cov, empirical_mean_seq\n",
    "        )\n",
    "        state = optimizer_update(step_index, grad, state)\n",
    "        return value, state\n",
    "    \n",
    "    state = optimizer_init(θ_0)\n",
    "\n",
    "    for s in range(n_steps):\n",
    "        _, state = optimizer_step(state, obs_path_particles, initial_mean, initial_cov, empirical_mean_seq, s)\n",
    "        # print(optimizer_get_params(state))\n",
    "        \n",
    "    return optimizer_get_params(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_iter):\n",
    "    print(f\"Iteration {i+1}\")\n",
    "    print(\"Compute the sample paths\")\n",
    "    xy_seq_particles_sim = run_simulation(seed=int(20250625+i), \n",
    "    num_particles=num_particles, num_steps=num_steps, dt=dt_sim, model_parameters=model_parameters, discard_steps=discard_steps)\n",
    "\n",
    "    x_seq_particles_sim = xy_seq_particles_sim[:, :, 0]  # Voltage variable\n",
    "    # Run simulation for each iteration\n",
    "    x_seq_particles_obs = x_seq_particles_sim[::sub_interval, :]  # Downsampled for observation\n",
    "\n",
    "    empirical_mean_seq = x_seq_particles_obs[:, :].mean(axis=1)  # Mean of v over time for all particles \n",
    "\n",
    "    showplots(x_seq_particles_sim, x_seq_particles_obs, t_seq_sim, t_seq_obs)\n",
    "\n",
    "    θ_0 = np.array([1.0, 1.0, 1.0, 1.0, 0.0])  # Initial guess for parameters  \n",
    "\n",
    "    \n",
    "    print(\"Optimising LG-based contrast estimator starts.\") \n",
    "    θ_seq_lg[:, i] = compute_contrast_estimator(\n",
    "        ips_fhn.get_contrast_function, x_seq_particles_obs, θ_0, initial_mean, initial_cov, empirical_mean_seq\n",
    "    )\n",
    "        \n",
    "    print(θ_seq_lg[:, i])\n",
    "    print(\"Optimising LG-based contrast estimator ends.\") \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Number of parameters\n",
    "num_parameters = θ_seq_lg.shape[0]\n",
    "\n",
    "# Create a single figure with subplots for relative errors of θ_seq_lg\n",
    "fig, axes = plt.subplots(1, num_parameters, figsize=(15, 5), sharey=True)  # Adjust width and height\n",
    "# fig.suptitle(\"Relative Errors of θ_seq_lg Parameters\", fontsize=16)\n",
    "\n",
    "reference_values = [model_parameters['alpha'], model_parameters['beta'], model_parameters['tau'], model_parameters['sigma'], model_parameters['kappa']]\n",
    "parameter_labels = ['α', 'β', 'τ', 'σ', 'κ']  # True labels from model_parameters\n",
    "\n",
    "for i in range(num_parameters):\n",
    "    # Data for LG relative errors for the current parameter\n",
    "    data = (θ_seq_lg[i, :] - reference_values[i]) / reference_values[i]\n",
    "    \n",
    "    # Create boxplot for the current parameter\n",
    "    axes[i].boxplot(data, labels=[parameter_labels[i]])\n",
    "    axes[i].grid(True)\n",
    "\n",
    "    # Overlay scattered points for LG\n",
    "    x_positions = np.random.normal(1, 0.05, size=len(data))  # Add slight jitter for better visualization\n",
    "    axes[i].scatter(x_positions, data, alpha=0.6, color='red', s=10, label='Data Points')\n",
    "\n",
    "# Add a shared y-axis label\n",
    "fig.text(0.04, 0.5, 'Relative Error', va='center', rotation='vertical')\n",
    "\n",
    "plt.tight_layout(rect=[0.05, 0, 1, 0.95])  # Adjust layout to fit the title\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine θ_seq_lg and θ_seq_em into a single DataFrame\n",
    "data = {\n",
    "    f\"LG_θ_{i+1}\": θ_seq_lg[i, :] for i in range(θ_seq_lg.shape[0])\n",
    "}\n",
    "data.update({\n",
    "    f\"EM_θ_{i+1}\": θ_seq_em[i, :] for i in range(θ_seq_em.shape[0])\n",
    "})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "output_file = \"ips_fhn_partial.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Data successfully written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
