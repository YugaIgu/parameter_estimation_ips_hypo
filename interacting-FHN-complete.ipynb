{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import symnum\n",
    "import symnum.numpy as snp\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, vmap, value_and_grad\n",
    "from jax.example_libraries.optimizers import adam\n",
    "import matplotlib.pyplot as plt\n",
    "# from jax.config import config\n",
    "# config.update('jax_enable_x64', True)\n",
    "# config.update('jax_platform_name', 'cpu')\n",
    "import density_ips_fhn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simulation-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Define the interaction term\n",
    "def interaction_term(v_i, v_j):\n",
    "    \"\"\"Compute the interaction term between two particles.\"\"\"\n",
    "    return v_j - v_i\n",
    "\n",
    "# Function to run a single simulation using JAX and scan\n",
    "def run_simulation(seed, num_particles, num_steps, dt, model_parameters, discard_steps=0):\n",
    "    # Set the random seed for reproducibility\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "\n",
    "    α = model_parameters['alpha']\n",
    "    β = model_parameters['beta']\n",
    "    τ = model_parameters['tau']\n",
    "    σ = model_parameters['sigma']\n",
    "    κ = model_parameters['kappa']\n",
    "\n",
    "    # Initialize variables\n",
    "    v = jnp.zeros(num_particles)  # Voltage-like variable\n",
    "    w = jnp.zeros(num_particles)  # Recovery-like variable\n",
    "\n",
    "    # Define the step function for scan\n",
    "    def step(carry, _):\n",
    "        v, w, key = carry\n",
    "\n",
    "        # Compute interaction terms using jax.vmap\n",
    "        def compute_interaction(v_all):\n",
    "            return jax.vmap(lambda v_i: jnp.sum(jax.vmap(lambda v_j: interaction_term(v_i, v_j))(v_all)))(v_all)\n",
    "\n",
    "        interaction = compute_interaction(v)\n",
    "\n",
    "        # Generate random noise\n",
    "        key, subkey = jax.random.split(key)\n",
    "        noise = jax.random.normal(subkey, shape=(num_particles,))\n",
    "\n",
    "        # Update FitzHugh-Nagumo equations with interaction and noise\n",
    "        dv = (v - v**3 / 3 - w + κ * interaction / num_particles) * dt + σ * jnp.sqrt(dt) * noise\n",
    "        dw = ((v + α - β * w) / τ) * dt\n",
    "\n",
    "        v = v + dv\n",
    "        w = w + dw\n",
    "\n",
    "        return (v, w, key), (v, w)\n",
    "\n",
    "    # Run the simulation using scan\n",
    "    (v_final, w_final, _), (v_history, w_history) = jax.lax.scan(step, (v, w, key), jnp.arange(num_steps))\n",
    "\n",
    "    # Combine v and w into pairs for each particle at each time step\n",
    "    vw_pairs = jnp.stack((v_history, w_history), axis=-1)  # Shape: (num_steps, num_particles, 2)\n",
    "    return vw_pairs[discard_steps:, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "\n",
    "def showplots(x_seq_sim, x_seq_obs, t_seq_sim, t_seq_obs):\n",
    "    \"\"\"Plot the voltage-like and recovery-like variables.\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(t_seq_sim, x_seq_sim[:, :, 0], '.', alpha=0.5, markersize=0.5)\n",
    "    plt.plot(t_seq_obs, x_seq_obs[:, :, 0], '.', alpha=0.5, markersize=0.5)\n",
    "    plt.title('Voltage-like Variable (v) Over Time')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('v')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(t_seq_sim, x_seq_sim[:, :, 1], '.', alpha=0.5, markersize=0.5)\n",
    "    plt.plot(t_seq_obs, x_seq_obs[:, :, 1], '.', alpha=0.5, markersize=0.5)\n",
    "    plt.title('Recovery-like Variable (w) Over Time')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('w')\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drift_func_rough(x, θ, empirical_mean):\n",
    "    *_, κ = θ\n",
    "\n",
    "    return snp.array([x[0] - x[0]**3/3 - x[1] - κ * (x[0] -  empirical_mean)]) \n",
    "    \n",
    "def drift_func_smooth(x, θ):\n",
    "    a, b, τ, *_ = θ\n",
    "\n",
    "    return snp.array([(x[0] + a - b * x[1]) / τ])\n",
    "\n",
    "def diff_coeff_rough(x, θ):\n",
    "    *_, σ, κ = θ\n",
    "    return snp.array([[σ]]) \n",
    "    \n",
    "def diff_coeff(x, θ):\n",
    "    *_, σ, κ = θ\n",
    "    return snp.array([[σ], [0]]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_x = 2\n",
    "dim_θ = 5\n",
    "\n",
    "symolic_log_transition_density_generators = {\n",
    "    'local_gaussian': density_ips_fhn.local_gaussian_log_transition_density,\n",
    "    'euler_maruyama': density_ips_fhn.euler_maruyama_log_transition_density_rough,\n",
    "}\n",
    "\n",
    "jax_log_transition_densities = {\n",
    "    key: symnum.numpify(dim_x, dim_x, dim_θ, None, None,numpy_module=jnp)(\n",
    "        symbolic_transition_density_generator(\n",
    "            drift_func_rough, drift_func_smooth, diff_coeff_rough\n",
    "        )\n",
    "    )\n",
    "    for key, symbolic_transition_density_generator in \n",
    "    symolic_log_transition_density_generators.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_likelihood_functions(log_transition_density):\n",
    "    @jit\n",
    "    # Function to compute the log-likelihood of θ given fixed indices, say for 'i'-th particle. Single particle over the time interval.\n",
    "\n",
    "    def log_likelihood_θ_fixed_index(θ, x_seq, t_seq, empirical_mean_seq):\n",
    "        log_transition_density_terms = vmap(log_transition_density, (0, 0, None, 0, 0))(\n",
    "            x_seq[1:], x_seq[:-1], θ, t_seq[1:] - t_seq[:-1], empirical_mean_seq[:-1]\n",
    "        )\n",
    "        return log_transition_density_terms.sum()\n",
    "    \n",
    "    @jit\n",
    "    # Full likelihood, which sums over all particles.\n",
    "    def log_likelihood_θ(θ, x_seq_particles, t_seq, empirical_mean_seq):\n",
    "        # Vectorized computation of log likelihood for all particles\n",
    "        log_likelihood_terms = jnp.sum(\n",
    "            vmap(log_likelihood_θ_fixed_index, (None, 1, None, None))(\n",
    "                θ, x_seq_particles, t_seq, empirical_mean_seq\n",
    "            )\n",
    "        )\n",
    "        return log_likelihood_terms\n",
    "            \n",
    "    return {'θ': log_likelihood_θ}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_complete_maximum_likelihood_estimates(\n",
    "    log_likelihood, t_seq, x_seq_particles, empirical_mean_seq, θ_0, optimizer=adam, n_steps=8000, step_size= 0.01):\n",
    "    optimizer_init, optimizer_update, optimizer_get_params = optimizer(step_size)\n",
    "    \n",
    "    @jit \n",
    "    def optimizer_step(step_index, state, x_seq_particles, t_seq, empirical_mean_seq):\n",
    "        value, grad = value_and_grad(log_likelihood[\"θ\"])(\n",
    "            optimizer_get_params(state), x_seq_particles, t_seq, empirical_mean_seq\n",
    "        )\n",
    "        state = optimizer_update(step_index, -grad, state)\n",
    "        return value, state\n",
    "\n",
    "    state = optimizer_init(θ_0)\n",
    "\n",
    "    for s in range(n_steps):\n",
    "        _, state = optimizer_step(s, state, x_seq_particles, t_seq, empirical_mean_seq)\n",
    "        # print(optimizer_get_params(state))\n",
    "        \n",
    "    return optimizer_get_params(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation setting \n",
    "num_particles = 100  # Number of particles\n",
    "dt_sim = 0.0005            # Time step for simulation \n",
    "dt_obs = 0.005           # Time step for observation (subsampling) \n",
    "num_steps = 60000     # Number of time steps for simulation\n",
    "discard_steps = 0 # Steps to discard for initial transients  \n",
    "\n",
    "# FitzHugh-Nagumo model parameters\n",
    "α = 0.2  # Parameter controlling excitability\n",
    "β = 0.8  # Parameter controlling recovery\n",
    "τ = 1.5  # Timescale for recovery variable\n",
    "σ = 0.5  # Noise strength\n",
    "κ = 2.0  # Strength of interaction between particles\n",
    "\n",
    "model_parameters = {'alpha': α, 'beta': β, 'tau': τ, 'sigma': σ, 'kappa': κ} \n",
    "\n",
    "num_iter = 100\n",
    "θ_seq_lg = np.zeros((5, num_iter))\n",
    "θ_seq_em = np.zeros((5, num_iter))\n",
    "\n",
    "log_likelihood_lg = get_log_likelihood_functions(jax_log_transition_densities['local_gaussian'])\n",
    "\n",
    "sub_interval = int(dt_obs/dt_sim) \n",
    "t_seq_sim = np.arange(discard_steps, num_steps) * dt_sim \n",
    "t_seq_obs = t_seq_sim[::sub_interval] \n",
    "\n",
    "for i in range(num_iter):\n",
    "    print(f\"Iteration {i+1}\")\n",
    "    print(\"Compute the sample paths\")\n",
    "    x_seq_particles_sim = run_simulation(seed=int(20250625+i), num_particles=num_particles, num_steps=num_steps, dt=dt_sim, model_parameters=model_parameters, discard_steps=discard_steps)\n",
    "    # Run simulation for each iteration\n",
    "    x_seq_particles_obs = x_seq_particles_sim[::sub_interval, :, :]  # Downsampled for observation\n",
    "\n",
    "    showplots(x_seq_particles_sim, x_seq_particles_obs,t_seq_sim, t_seq_obs)\n",
    "\n",
    "    empirical_mean_seq = x_seq_particles_obs[:, :, 0].mean(axis=1)  # Mean of v over time for all particles\n",
    "\n",
    "    θ_0_lg = np.array([1.0, 1.0, 1.0, 1.0, 0.0])  # Initial guess for parameters \n",
    "\n",
    "    print(\"Optimising LG-based contrast estimator starts.\") \n",
    "    θ_seq_lg[:, i] = compute_complete_maximum_likelihood_estimates(\n",
    "        log_likelihood_lg, t_seq_obs, x_seq_particles_obs, empirical_mean_seq, θ_0_lg\n",
    "    )\n",
    "    print(θ_seq_lg[:, i])\n",
    "\n",
    "    print(\"Likelihood value and gradient with estimated parameters:\")\n",
    "    print(value_and_grad(log_likelihood_lg[\"θ\"])(\n",
    "            θ_seq_lg[:, i], x_seq_particles_obs, t_seq_obs, empirical_mean_seq\n",
    "        ))\n",
    "    print(\"Optimising LG-based contrast estimator ends.\") \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Number of parameters\n",
    "num_parameters = θ_seq_lg.shape[0]\n",
    "\n",
    "# Create a single figure with subplots for relative errors of θ_seq_lg\n",
    "fig, axes = plt.subplots(1, num_parameters, figsize=(15, 5), sharey=True)  # Adjust width and height\n",
    "fig.suptitle(\"Relative Errors of θ_seq_lg Parameters\", fontsize=16)\n",
    "\n",
    "reference_values = [model_parameters['alpha'], model_parameters['beta'], model_parameters['tau'], model_parameters['sigma'], model_parameters['kappa']]\n",
    "parameter_labels = ['α', 'β', 'τ', 'σ', 'κ']  # True labels from model_parameters\n",
    "\n",
    "for i in range(num_parameters):\n",
    "    # Data for LG relative errors for the current parameter\n",
    "    data = (θ_seq_lg[i, :] - reference_values[i]) / reference_values[i]\n",
    "    \n",
    "    # Create boxplot for the current parameter\n",
    "    axes[i].boxplot(data, labels=[parameter_labels[i]])\n",
    "    axes[i].grid(True)\n",
    "\n",
    "    # Overlay scattered points for LG\n",
    "    x_positions = np.random.normal(1, 0.05, size=len(data))  # Add slight jitter for better visualization\n",
    "    axes[i].scatter(x_positions, data, alpha=0.6, color='red', s=10, label='Data Points')\n",
    "\n",
    "# Add a shared y-axis label\n",
    "fig.text(0.04, 0.5, 'Relative Error', va='center', rotation='vertical')\n",
    "\n",
    "plt.tight_layout(rect=[0.05, 0, 1, 0.95])  # Adjust layout to fit the title\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Create a figure for the boxplot of σ\n",
    "# fig, ax = plt.subplots(figsize=(4, 4))\n",
    "# fig.suptitle(\"Boxplots of Diffusion Parameter\", fontsize=16)\n",
    "\n",
    "# reference_value = model_parameters['sigma']  # True value of σ\n",
    "\n",
    "# # Data for LG and EM relative errors for σ\n",
    "# lg_data = (θ_seq_lg[3, :] - reference_value) / reference_value\n",
    "# em_data = (θ_seq_em[3, :] - reference_value) / reference_value\n",
    "\n",
    "# # Create boxplot for σ\n",
    "# ax.boxplot([lg_data, em_data], labels=['LG', 'EM'])\n",
    "# ax.grid(True)\n",
    "\n",
    "# # Overlay scattered points for LG and EM\n",
    "# lg_positions = np.random.normal(1, 0.05, size=len(lg_data))  # Add slight jitter for LG\n",
    "# em_positions = np.random.normal(2, 0.05, size=len(em_data))  # Add slight jitter for EM\n",
    "# ax.scatter(lg_positions, lg_data, alpha=0.6, color='red', s=10, label='LG Data Points')\n",
    "# ax.scatter(em_positions, em_data, alpha=0.6, color='blue', s=10, label='EM Data Points')\n",
    "\n",
    "# # Add y-axis label\n",
    "# ax.set_ylabel('Relative Error')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine θ_seq_lg and θ_seq_em into a single DataFrame\n",
    "data = {\n",
    "    f\"LG_θ_{i+1}\": θ_seq_lg[i, :] for i in range(θ_seq_lg.shape[0])\n",
    "}\n",
    "\n",
    "# data.update({\n",
    "#     f\"EM_θ_{i+1}\": θ_seq_em[i, :] for i in range(θ_seq_em.shape[0])\n",
    "# })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "output_file = \"theta_sequences_ips_fhn_fourth_trial.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Data successfully written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
